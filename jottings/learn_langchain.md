# å¦‚ä½•è§„å®š LLM è¾“å‡ºçš„ JSON æ ¼å¼

åœ¨ LangChain å¼€å‘ä¸­ï¼Œè®© LLM ç¨³å®šè¾“å‡ºç»“æ„åŒ–æ•°æ®ï¼ˆå¦‚ JSONï¼‰æ˜¯æ ¸å¿ƒéš¾ç‚¹ã€‚ä¸»è¦æœ‰ä¸¤ç§æµæ´¾ï¼š

## 1. è½¯é™åˆ¶ (Soft Constraints) - Prompt Engineering

ä½¿ç”¨ `JsonOutputParser`ã€‚

**åŸç†**ï¼š
é€šè¿‡ Prompt Engineeringï¼Œåœ¨ Prompt æœ«å°¾æ³¨å…¥ä¸€æ®µæ ¼å¼è¯´æ˜ï¼ˆ`format_instructions`ï¼‰ï¼Œâ€œæ±‚â€æ¨¡å‹è¾“å‡º JSONã€‚

**ä»£ç ç¤ºä¾‹**ï¼š
```python
from langchain_core.output_parsers import JsonOutputParser

# 1. å®šä¹‰è§£æå™¨
parser = JsonOutputParser(pydantic_object=UICommand)

# 2. å®šä¹‰ Prompt (å¿…é¡»åŒ…å« format_instructions å ä½ç¬¦)
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant.\n{format_instructions}"),
    ("user", "{text}")
]).partial(format_instructions=parser.get_format_instructions()) # ä½¿ç”¨ partial æ³¨å…¥

# 3. æ„å»ºé“¾
chain = prompt | llm | parser
```

### ğŸ’¡ è¿›é˜¶æŠ€å·§ï¼šä½¿ç”¨ `.partial()` "ç„Šæ­»" å˜é‡

åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† `.partial(format_instructions=...)`ã€‚

**ä¸ºä»€ä¹ˆè¦è¿™ä¹ˆåšï¼Ÿ**
Prompt æ¨¡æ¿é‡Œæœ‰ `{format_instructions}` è¿™ä¸ªå ä½ç¬¦ã€‚å¦‚æœä¸å¤„ç†ï¼Œæ¯æ¬¡è°ƒç”¨ `chain.invoke` æ—¶éƒ½å¿…é¡»æ‰‹åŠ¨ä¼ è¿›å»ï¼š
```python
# ç¬¨åŠæ³•ï¼šæ¯æ¬¡éƒ½è¦ä¼ 
chain.invoke({
    "text": "...", 
    "format_instructions": parser.get_format_instructions() # ç´¯èµ˜ï¼
})
```

**`.partial()` çš„ä½œç”¨**ï¼š
å®ƒåƒ Python çš„ `functools.partial` ä¸€æ ·ï¼Œ**æå‰å¡«å……**éƒ¨åˆ†å˜é‡ï¼Œç”Ÿæˆä¸€ä¸ªæ–°çš„ Prompt æ¨¡æ¿ã€‚
```python
# èªæ˜åŠæ³•ï¼šæå‰ç„Šæ­»
prompt = raw_prompt.partial(format_instructions=parser.get_format_instructions())

# è°ƒç”¨æ—¶æ¸…çˆ½å¤šäº†
chain.invoke({"text": "..."})
```

**æ‰§è¡Œæ—¶æœº**ï¼š
è¿™ä¸ªâ€œç„Šæ­»â€çš„æ“ä½œæ˜¯åœ¨**ä»£ç å®šä¹‰é˜¶æ®µ**ï¼ˆè§£é‡Šå™¨æ‰§è¡Œåˆ°è¿™ä¸€è¡Œæ—¶ï¼‰å°±å®Œæˆäº†ã€‚
è¿™æ„å‘³ç€ `parser.get_format_instructions()` åªä¼šè¿è¡Œä¸€æ¬¡ã€‚ç­‰åˆ°çœŸæ­£å¤„ç†ç”¨æˆ·è¯·æ±‚ï¼ˆ`invoke`ï¼‰æ—¶ï¼ŒPrompt é‡Œå·²ç»åŒ…å«äº†å®Œæ•´çš„æ ¼å¼è¯´æ˜ï¼Œä¸éœ€è¦å†åŠ¨æ€è®¡ç®—æˆ–ä¼ é€’äº†ã€‚

---

## 2. ç¡¬é™åˆ¶ (Hard Constraints) - Function Calling

ä½¿ç”¨ `with_structured_output`ã€‚

**åŸç†**ï¼š
åˆ©ç”¨ç°ä»£æ¨¡å‹ï¼ˆOpenAI, DeepSeek, Claude 3ï¼‰åŸç”Ÿçš„ **Function Calling (Tool Use)** èƒ½åŠ›ã€‚ç›´æ¥åœ¨åº•å±‚ API å±‚é¢å¼ºåˆ¶æ¨¡å‹è°ƒç”¨ä¸€ä¸ªâ€œè¾“å‡ºå‡½æ•°â€ï¼Œå‚æ•°å¿…é¡»ç¬¦åˆ Schemaã€‚

**ä»£ç ç¤ºä¾‹**ï¼š
```python
# 1. å®šä¹‰ç»“æ„åŒ– LLM (ç›´æ¥ç»‘å®š Pydantic æ¨¡å‹)
structured_llm = llm.with_structured_output(UICommand)

# 2. å®šä¹‰ Prompt (ä¸éœ€è¦ format_instructions äº†ï¼)
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant. Extract the user's intent."),
    ("user", "{text}")
])

# 3. æ„å»ºé“¾
chain = prompt | structured_llm
```

**ç‰¹ç‚¹**ï¼š
*   âœ… **æåº¦ç¨³å®š**ï¼šæ¨¡å‹å¾®è°ƒè¿‡ï¼Œä¸¥æ ¼éµå®ˆ Schemaï¼Œå‡ ä¹ä¸å‡ºé”™ã€‚
*   âœ… **çœ Token**ï¼šä¸éœ€è¦åœ¨ Prompt é‡Œå†™æ ¼å¼è¯´æ˜ã€‚
*   âœ… **ä»£ç å¹²å‡€**ï¼šé€»è¾‘æ›´è‡ªç„¶ã€‚
*   âŒ **æ¨¡å‹ä¾èµ–**ï¼šå¿…é¡»ä½¿ç”¨æ”¯æŒ Function Calling çš„æ¨¡å‹ã€‚

---

## æ€»ç»“

| ç‰¹æ€§ | JsonOutputParser (è½¯) | with_structured_output (ç¡¬) |
| :--- | :--- | :--- |
| **åŸç†** | Prompt æç¤ºè¯ | åº•å±‚ API (Function Calling) |
| **ç¨³å®šæ€§** | ä¸­ (ä¾èµ–æ¨¡å‹æŒ‡ä»¤éµå¾ªèƒ½åŠ›) | é«˜ (å¼ºåˆ¶çº¦æŸ) |
| **Token æ¶ˆè€—** | é«˜ (Prompt å˜é•¿) | ä½ |
| **é€‚ç”¨æ¨¡å‹** | æ‰€æœ‰ LLM | OpenAI, DeepSeek, Claude ç­‰ç°ä»£æ¨¡å‹ |
| **æ¨èåœºæ™¯** | åªæœ‰æ™®é€šè¡¥å…¨èƒ½åŠ›çš„æ¨¡å‹ | **ç”Ÿäº§ç¯å¢ƒé¦–é€‰** (åªè¦æ¨¡å‹æ”¯æŒ) |